{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title Click to install the necessary packages. It may take a while. {display-mode: \"form\"}\n",
        "%%capture\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "!pip install ffmpeg-python\n",
        "!pip install IPython\n",
        "!pip install pydub\n",
        "!pip install -U openai-whisper\n",
        "!pip install praat-parselmouth"
      ],
      "metadata": {
        "id": "vEP4d8BHAZf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Click to record the audio. Try saying \"I like this product\" in a certain or uncertain tone. {display-mode: \"form\"}\n",
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "import io\n",
        "import ffmpeg\n",
        "%%capture\n",
        "# Reference: https://www.youtube.com/watch?v=4DGkgUffWxs\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = 0;\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "\n",
        "      mimeType : 'audio/webm;codecs=opus'\n",
        "  };\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {\n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = true;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data);\n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "    }\n",
        "  };\n",
        "  recorder.start();\n",
        "  };\n",
        "\n",
        "recordButton.innerText = \"Recording... press to stop\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "function toggleRecording() {\n",
        "  if (recorder && recorder.state == \"recording\") {\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      recordButton.innerText = \"You can play the recording!\"\n",
        "  }\n",
        "}\n",
        "// https://stackoverflow.com/a/951057\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "//recordButton.addEventListener(\"click\", toggleRecording);\n",
        "recordButton.onclick = ()=>{\n",
        "toggleRecording()\n",
        "\n",
        "sleep(2000).then(() => {\n",
        "  resolve(base64data.toString())\n",
        "\n",
        "});\n",
        "\n",
        "}\n",
        "});\n",
        "\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  pricess=(ffmpeg.input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True))\n",
        "  output, err = pricess.communicate(input=binary)\n",
        "  riff_chunk_size = len(output) - 8\n",
        "  q=riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "  riff=output[:4] + bytes(b) + output[8:]\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "  return audio, sr\n",
        "audio, sr = get_audio()"
      ],
      "metadata": {
        "id": "-JqcGxvxPOsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Or click to upload the audio {display-mode: \"form\"}\n",
        "from google.colab import files\n",
        "import io\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "from pydub import AudioSegment\n",
        "import numpy as np\n",
        "def upload_and_read_single_audio():\n",
        "    print(\"Please upload a single audio file (.wav or .mp3):\")\n",
        "    uploaded = files.upload()  # User uploads a file\n",
        "\n",
        "    # Check if more than one file was uploaded\n",
        "    if len(uploaded) != 1:\n",
        "        print(\"Please upload only one audio file at a time.\")\n",
        "        return None\n",
        "    file_name, file_data = next(iter(uploaded.items()))\n",
        "    try:\n",
        "        if file_name.lower().endswith('.wav'):\n",
        "            # Use scipy.io.wavfile.read for WAV files\n",
        "            sr, audio = wav_read(io.BytesIO(file_data))\n",
        "            if audio.ndim == 2:  # Check if audio is stereo\n",
        "                audio = audio.mean(axis=1)  # Convert to mono by averaging both channels\n",
        "            print(f\"Loaded {file_name} successfully with sample rate {sr} Hz.\")\n",
        "            return sr, audio\n",
        "        elif file_name.lower().endswith('.mp3'):\n",
        "            # Use pydub to handle MP3 files\n",
        "            audio_segment = AudioSegment.from_file(io.BytesIO(file_data), format='mp3')\n",
        "            sr = audio_segment.frame_rate\n",
        "            # Convert audio segment to numpy array\n",
        "            samples = np.array(audio_segment.get_array_of_samples())\n",
        "            if audio_segment.channels == 2:\n",
        "                samples = samples.reshape((-1, 2))\n",
        "                samples = samples.mean(axis=1)  # Convert to mono by averaging both channels\n",
        "            print(f\"Loaded {file_name} successfully with sample rate {sr} Hz.\")\n",
        "            return sr, samples.astype(np.int16)  # Ensure dtype is int16 for consistency with scipy.io.wavfile\n",
        "        else:\n",
        "            print(f\"Unsupported file type uploaded: {file_name}. Please upload only .wav or .mp3 files.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load {file_name}: {e}\")\n",
        "\n",
        "sr, audio = upload_and_read_single_audio()\n"
      ],
      "metadata": {
        "id": "HrfxzzqA8jCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Click to predict certainty degree from the recorded or uploaded audio { display-mode: \"form\" }\n",
        "%%capture\n",
        "import whisper\n",
        "from scipy.io.wavfile import write as wav_write\n",
        "import tempfile\n",
        "from scipy.interpolate import CubicSpline\n",
        "import parselmouth\n",
        "from parselmouth.praat import call\n",
        "import joblib\n",
        "import torch\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\"\"\"def predict_text_from_audio(filename):\n",
        "    model = whisper.load_model(\"base\")  # Load the Whisper model\n",
        "    # Create a temporary WAV file to handle audio correctly\n",
        "    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=True) as tmpfile:\n",
        "        model.to(DEVICE)\n",
        "        result = model.transcribe(filename)\n",
        "        return result[\"text\"]\n",
        "predicted_text = predict_text_from_audio(filename)\"\"\"\n",
        "#prepress the audio for uncertainty prediction\n",
        "def F0_contour(file_name):\n",
        "    sound = parselmouth.Sound(file_name)\n",
        "    Topitch=call(sound,\"To Pitch (ac)\",0.01, 80.0, 5,1, 0.03, 0.6, 0.03,0.6,0.14,300)\n",
        "    F0_values=Topitch.selected_array['frequency']\n",
        "    F0_times=Topitch.ts()\n",
        "    F0_times, F0_values = zip(*((x, y) for x, y in zip(F0_times, F0_values) if str(y)!=\"nan\" and y>0.0))\n",
        "    xarray = np.array(F0_times)\n",
        "    yarray = np.array(F0_values)\n",
        "    data = np.column_stack([xarray, yarray])\n",
        "    return [xarray, yarray]\n",
        "time_F0s=F0_contour(filename)\n",
        "\n",
        "def compute_cspline_DFT(time_F0s):\n",
        "    F0_times=time_F0s[0]\n",
        "    F0_values=time_F0s[1]\n",
        "    F0_time_normalized_0_1=(F0_times - F0_times[0]) / (F0_times[-1] - F0_times[0])\n",
        "    f = CubicSpline(F0_time_normalized_0_1, F0_values, bc_type=\"natural\")\n",
        "    x_new = np.linspace(0, 1, 400) # parameter=400\n",
        "    y_new = f(x_new)\n",
        "    f=np.fft.fft(y_new)[:10]\n",
        "    f=f/np.abs(f[0])# Normalize the FFT by the magnitude of the zero frequency\n",
        "    f_all=[]\n",
        "    for i in f:\n",
        "        f_all=f_all+[np.abs(i),np.abs(i)*np.angle(i)]\n",
        "    return f_all\n",
        "model_input=compute_cspline_DFT(time_F0s)\n",
        "uncertainty_classifier = joblib.load('/content/drive/My Drive/JM_1st_R_R/New Code/random_forest_maxdepth20_short_medium_long_parameter0.62_1.pkl')\n",
        "predcted_uncertainty=uncertainty_classifier.predict_proba([model_input])[:,1][0]"
      ],
      "metadata": {
        "id": "xYyw5dvkGqgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Click to see the transcription and certainty degree {display-mode: \"form\"}\n",
        "print(\"Transcription: \",predicted_text)\n",
        "print(\"Certainty degree (0-extremely uncertain; 1-extremely certain)\",predcted_uncertainty)"
      ],
      "metadata": {
        "id": "ufvvam2aVNmD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}